{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c35c34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:36.807961Z",
     "iopub.status.busy": "2024-07-05T07:38:36.807169Z",
     "iopub.status.idle": "2024-07-05T07:38:37.688453Z",
     "shell.execute_reply": "2024-07-05T07:38:37.687489Z"
    },
    "papermill": {
     "duration": 0.896772,
     "end_time": "2024-07-05T07:38:37.690878",
     "exception": false,
     "start_time": "2024-07-05T07:38:36.794106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/transformers/facebook-bart-large/config.json\n",
      "/kaggle/input/transformers/facebook-bart-large/tokenizer.json\n",
      "/kaggle/input/transformers/facebook-bart-large/pytorch_model.bin\n",
      "/kaggle/input/transformers/bert-large-uncased/config.json\n",
      "/kaggle/input/transformers/bert-large-uncased/tokenizer.json\n",
      "/kaggle/input/transformers/bert-large-uncased/pytorch_model.bin\n",
      "/kaggle/input/transformers/roberta-base/config.json\n",
      "/kaggle/input/transformers/roberta-base/tokenizer.json\n",
      "/kaggle/input/transformers/roberta-base/pytorch_model.bin\n",
      "/kaggle/input/transformers/distilroberta-base/config.json\n",
      "/kaggle/input/transformers/distilroberta-base/tokenizer.json\n",
      "/kaggle/input/transformers/distilroberta-base/pytorch_model.bin\n",
      "/kaggle/input/transformers/distilbert-base-uncased/config.json\n",
      "/kaggle/input/transformers/distilbert-base-uncased/tokenizer.json\n",
      "/kaggle/input/transformers/distilbert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/transformers/xlnet-base-cased/config.json\n",
      "/kaggle/input/transformers/xlnet-base-cased/tokenizer.json\n",
      "/kaggle/input/transformers/xlnet-base-cased/pytorch_model.bin\n",
      "/kaggle/input/transformers/funnel-transformer-small/config.json\n",
      "/kaggle/input/transformers/funnel-transformer-small/tokenizer.json\n",
      "/kaggle/input/transformers/funnel-transformer-small/pytorch_model.bin\n",
      "/kaggle/input/transformers/t5-base/config.json\n",
      "/kaggle/input/transformers/t5-base/tokenizer.json\n",
      "/kaggle/input/transformers/t5-base/pytorch_model.bin\n",
      "/kaggle/input/transformers/facebook-bart-base/config.json\n",
      "/kaggle/input/transformers/facebook-bart-base/tokenizer.json\n",
      "/kaggle/input/transformers/facebook-bart-base/pytorch_model.bin\n",
      "/kaggle/input/transformers/bert-base-uncased/config.json\n",
      "/kaggle/input/transformers/bert-base-uncased/tokenizer.json\n",
      "/kaggle/input/transformers/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/transformers/roberta-large/config.json\n",
      "/kaggle/input/transformers/roberta-large/tokenizer.json\n",
      "/kaggle/input/transformers/roberta-large/pytorch_model.bin\n",
      "/kaggle/input/transformers/google-electra-base-discriminator/config.json\n",
      "/kaggle/input/transformers/google-electra-base-discriminator/tokenizer.json\n",
      "/kaggle/input/transformers/google-electra-base-discriminator/pytorch_model.bin\n",
      "/kaggle/input/transformers/funnel-transformer-large/config.json\n",
      "/kaggle/input/transformers/funnel-transformer-large/tokenizer.json\n",
      "/kaggle/input/transformers/funnel-transformer-large/pytorch_model.bin\n",
      "/kaggle/input/transformers/xlnet-large-cased/config.json\n",
      "/kaggle/input/transformers/xlnet-large-cased/tokenizer.json\n",
      "/kaggle/input/transformers/xlnet-large-cased/pytorch_model.bin\n",
      "/kaggle/input/transformers/albert-large-v2/config.json\n",
      "/kaggle/input/transformers/albert-large-v2/tokenizer.json\n",
      "/kaggle/input/transformers/albert-large-v2/pytorch_model.bin\n",
      "/kaggle/input/transformers/t5-large/config.json\n",
      "/kaggle/input/transformers/t5-large/tokenizer.json\n",
      "/kaggle/input/transformers/t5-large/pytorch_model.bin\n",
      "/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/train.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3f7b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:37.714695Z",
     "iopub.status.busy": "2024-07-05T07:38:37.714305Z",
     "iopub.status.idle": "2024-07-05T07:38:46.332540Z",
     "shell.execute_reply": "2024-07-05T07:38:46.331666Z"
    },
    "papermill": {
     "duration": 8.632043,
     "end_time": "2024-07-05T07:38:46.334723",
     "exception": false,
     "start_time": "2024-07-05T07:38:37.702680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import regex as re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import RobertaTokenizer, AutoModel,AutoTokenizer,AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1df4f35",
   "metadata": {
    "papermill": {
     "duration": 0.010853,
     "end_time": "2024-07-05T07:38:46.357019",
     "exception": false,
     "start_time": "2024-07-05T07:38:46.346166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35d657d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:46.381948Z",
     "iopub.status.busy": "2024-07-05T07:38:46.381407Z",
     "iopub.status.idle": "2024-07-05T07:38:46.386803Z",
     "shell.execute_reply": "2024-07-05T07:38:46.385827Z"
    },
    "papermill": {
     "duration": 0.020404,
     "end_time": "2024-07-05T07:38:46.388886",
     "exception": false,
     "start_time": "2024-07-05T07:38:46.368482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path     = \"/kaggle/input/lmsys-chatbot-arena/train.csv\"\n",
    "test_path      = \"/kaggle/input/lmsys-chatbot-arena/test.csv\"\n",
    "model_path     = '../input/transformers/roberta-base'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53e6a5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:46.412587Z",
     "iopub.status.busy": "2024-07-05T07:38:46.412322Z",
     "iopub.status.idle": "2024-07-05T07:38:49.967887Z",
     "shell.execute_reply": "2024-07-05T07:38:49.966671Z"
    },
    "papermill": {
     "duration": 3.570685,
     "end_time": "2024-07-05T07:38:49.970917",
     "exception": false,
     "start_time": "2024-07-05T07:38:46.400232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "test  = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62079924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:49.998129Z",
     "iopub.status.busy": "2024-07-05T07:38:49.997793Z",
     "iopub.status.idle": "2024-07-05T07:38:50.025908Z",
     "shell.execute_reply": "2024-07-05T07:38:50.024988Z"
    },
    "papermill": {
     "duration": 0.042769,
     "end_time": "2024-07-05T07:38:50.028067",
     "exception": false,
     "start_time": "2024-07-05T07:38:49.985298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255737a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:50.052811Z",
     "iopub.status.busy": "2024-07-05T07:38:50.052484Z",
     "iopub.status.idle": "2024-07-05T07:38:50.056468Z",
     "shell.execute_reply": "2024-07-05T07:38:50.055659Z"
    },
    "papermill": {
     "duration": 0.018611,
     "end_time": "2024-07-05T07:38:50.058641",
     "exception": false,
     "start_time": "2024-07-05T07:38:50.040030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_columns = ['winner_model_a', 'winner_model_b', 'winner_tie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6277987b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:50.083135Z",
     "iopub.status.busy": "2024-07-05T07:38:50.082850Z",
     "iopub.status.idle": "2024-07-05T07:38:50.118438Z",
     "shell.execute_reply": "2024-07-05T07:38:50.117757Z"
    },
    "papermill": {
     "duration": 0.050305,
     "end_time": "2024-07-05T07:38:50.120455",
     "exception": false,
     "start_time": "2024-07-05T07:38:50.070150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = train[target_columns].idxmax(axis=1) \n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4cae3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:50.144792Z",
     "iopub.status.busy": "2024-07-05T07:38:50.144482Z",
     "iopub.status.idle": "2024-07-05T07:38:50.201475Z",
     "shell.execute_reply": "2024-07-05T07:38:50.200613Z"
    },
    "papermill": {
     "duration": 0.071635,
     "end_time": "2024-07-05T07:38:50.203652",
     "exception": false,
     "start_time": "2024-07-05T07:38:50.132017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor(y_encoded, dtype=torch.int64)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04540a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:50.229065Z",
     "iopub.status.busy": "2024-07-05T07:38:50.228603Z",
     "iopub.status.idle": "2024-07-05T07:38:51.610746Z",
     "shell.execute_reply": "2024-07-05T07:38:51.609901Z"
    },
    "papermill": {
     "duration": 1.397687,
     "end_time": "2024-07-05T07:38:51.613387",
     "exception": false,
     "start_time": "2024-07-05T07:38:50.215700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"all\"] = train.apply(lambda train: f\"User prompt: {train['prompt']}\\n\\nModel A :\\n{train['response_a']}\\n\\n--------\\n\\nModel B:\\n{train['response_b']}\", axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98ed3dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:51.640210Z",
     "iopub.status.busy": "2024-07-05T07:38:51.639858Z",
     "iopub.status.idle": "2024-07-05T07:38:51.646062Z",
     "shell.execute_reply": "2024-07-05T07:38:51.645081Z"
    },
    "papermill": {
     "duration": 0.021916,
     "end_time": "2024-07-05T07:38:51.648333",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.626417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test[\"all\"] =test.apply(lambda test: f\"User prompt: {test['prompt']}\\n\\nModel A :\\n{test['response_a']}\\n\\n--------\\n\\nModel B:\\n{test['response_b']}\", axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6acbe20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:51.673745Z",
     "iopub.status.busy": "2024-07-05T07:38:51.673486Z",
     "iopub.status.idle": "2024-07-05T07:38:51.678983Z",
     "shell.execute_reply": "2024-07-05T07:38:51.677990Z"
    },
    "papermill": {
     "duration": 0.020078,
     "end_time": "2024-07-05T07:38:51.681088",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.661010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train=train[\"all\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38b13dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:51.707074Z",
     "iopub.status.busy": "2024-07-05T07:38:51.706788Z",
     "iopub.status.idle": "2024-07-05T07:38:51.711234Z",
     "shell.execute_reply": "2024-07-05T07:38:51.710408Z"
    },
    "papermill": {
     "duration": 0.019842,
     "end_time": "2024-07-05T07:38:51.713378",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.693536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test=test[\"all\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcaf73a",
   "metadata": {
    "papermill": {
     "duration": 0.012062,
     "end_time": "2024-07-05T07:38:51.738873",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.726811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare data for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda14835",
   "metadata": {
    "papermill": {
     "duration": 0.011825,
     "end_time": "2024-07-05T07:38:51.762764",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.750939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1-load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44443a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:51.788645Z",
     "iopub.status.busy": "2024-07-05T07:38:51.788027Z",
     "iopub.status.idle": "2024-07-05T07:38:51.955264Z",
     "shell.execute_reply": "2024-07-05T07:38:51.954150Z"
    },
    "papermill": {
     "duration": 0.183266,
     "end_time": "2024-07-05T07:38:51.957958",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.774692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f5d668b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:38:51.984028Z",
     "iopub.status.busy": "2024-07-05T07:38:51.983460Z",
     "iopub.status.idle": "2024-07-05T07:40:14.996477Z",
     "shell.execute_reply": "2024-07-05T07:40:14.995651Z"
    },
    "papermill": {
     "duration": 83.028564,
     "end_time": "2024-07-05T07:40:14.999024",
     "exception": false,
     "start_time": "2024-07-05T07:38:51.970460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, return_tensors=\"pt\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cd971e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.025151Z",
     "iopub.status.busy": "2024-07-05T07:40:15.024810Z",
     "iopub.status.idle": "2024-07-05T07:40:15.038369Z",
     "shell.execute_reply": "2024-07-05T07:40:15.037622Z"
    },
    "papermill": {
     "duration": 0.028784,
     "end_time": "2024-07-05T07:40:15.040473",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.011689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, return_tensors=\"pt\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "408610e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.065862Z",
     "iopub.status.busy": "2024-07-05T07:40:15.065579Z",
     "iopub.status.idle": "2024-07-05T07:40:15.077185Z",
     "shell.execute_reply": "2024-07-05T07:40:15.076224Z"
    },
    "papermill": {
     "duration": 0.027397,
     "end_time": "2024-07-05T07:40:15.079290",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.051893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 44518, 14302,  ...,   209,  1797,     2],\n",
       "        [    0, 44518, 14302,  ...,  9889,     6,     2],\n",
       "        [    0, 44518, 14302,  ..., 12905, 43797,     2],\n",
       "        ...,\n",
       "        [    0, 44518, 14302,  ...,  2139, 48347,     2],\n",
       "        [    0, 44518, 14302,  ...,     1,     1,     1],\n",
       "        [    0, 44518, 14302,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0c5f",
   "metadata": {
    "papermill": {
     "duration": 0.0123,
     "end_time": "2024-07-05T07:40:15.103333",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.091033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2-custom dataset for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4891ee4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.128703Z",
     "iopub.status.busy": "2024-07-05T07:40:15.128431Z",
     "iopub.status.idle": "2024-07-05T07:40:15.134731Z",
     "shell.execute_reply": "2024-07-05T07:40:15.133875Z"
    },
    "papermill": {
     "duration": 0.021426,
     "end_time": "2024-07-05T07:40:15.136631",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.115205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1ae9a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.161777Z",
     "iopub.status.busy": "2024-07-05T07:40:15.161477Z",
     "iopub.status.idle": "2024-07-05T07:40:15.165627Z",
     "shell.execute_reply": "2024-07-05T07:40:15.164735Z"
    },
    "papermill": {
     "duration": 0.019185,
     "end_time": "2024-07-05T07:40:15.167845",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.148660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb32cd9",
   "metadata": {
    "papermill": {
     "duration": 0.011831,
     "end_time": "2024-07-05T07:40:15.191339",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.179508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2-custom dataset for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1494bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.216747Z",
     "iopub.status.busy": "2024-07-05T07:40:15.216441Z",
     "iopub.status.idle": "2024-07-05T07:40:15.222350Z",
     "shell.execute_reply": "2024-07-05T07:40:15.221407Z"
    },
    "papermill": {
     "duration": 0.021014,
     "end_time": "2024-07-05T07:40:15.224487",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.203473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab91c7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.249276Z",
     "iopub.status.busy": "2024-07-05T07:40:15.248942Z",
     "iopub.status.idle": "2024-07-05T07:40:15.253123Z",
     "shell.execute_reply": "2024-07-05T07:40:15.252140Z"
    },
    "papermill": {
     "duration": 0.019097,
     "end_time": "2024-07-05T07:40:15.255156",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.236059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomTestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c58ab6",
   "metadata": {
    "papermill": {
     "duration": 0.011852,
     "end_time": "2024-07-05T07:40:15.279194",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.267342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1376f687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.304809Z",
     "iopub.status.busy": "2024-07-05T07:40:15.304551Z",
     "iopub.status.idle": "2024-07-05T07:40:15.311454Z",
     "shell.execute_reply": "2024-07-05T07:40:15.310571Z"
    },
    "papermill": {
     "duration": 0.022267,
     "end_time": "2024-07-05T07:40:15.313562",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.291295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b4616",
   "metadata": {
    "papermill": {
     "duration": 0.011847,
     "end_time": "2024-07-05T07:40:15.337225",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.325378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eb56acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.363076Z",
     "iopub.status.busy": "2024-07-05T07:40:15.362838Z",
     "iopub.status.idle": "2024-07-05T07:40:15.366680Z",
     "shell.execute_reply": "2024-07-05T07:40:15.365715Z"
    },
    "papermill": {
     "duration": 0.018969,
     "end_time": "2024-07-05T07:40:15.368461",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.349492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a2a8776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:15.394356Z",
     "iopub.status.busy": "2024-07-05T07:40:15.394071Z",
     "iopub.status.idle": "2024-07-05T07:40:19.582655Z",
     "shell.execute_reply": "2024-07-05T07:40:19.581625Z"
    },
    "papermill": {
     "duration": 4.204085,
     "end_time": "2024-07-05T07:40:19.585073",
     "exception": false,
     "start_time": "2024-07-05T07:40:15.380988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../input/transformers/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels=num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6aecd30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:19.611438Z",
     "iopub.status.busy": "2024-07-05T07:40:19.611063Z",
     "iopub.status.idle": "2024-07-05T07:40:20.023423Z",
     "shell.execute_reply": "2024-07-05T07:40:20.022459Z"
    },
    "papermill": {
     "duration": 0.427747,
     "end_time": "2024-07-05T07:40:20.025962",
     "exception": false,
     "start_time": "2024-07-05T07:40:19.598215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,num_training_steps=len(train_loader) * num_epochs)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c94c6c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T07:40:20.052430Z",
     "iopub.status.busy": "2024-07-05T07:40:20.052087Z",
     "iopub.status.idle": "2024-07-05T11:58:35.004561Z",
     "shell.execute_reply": "2024-07-05T11:58:35.003431Z"
    },
    "papermill": {
     "duration": 15494.968356,
     "end_time": "2024-07-05T11:58:35.007331",
     "exception": false,
     "start_time": "2024-07-05T07:40:20.038975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/136545975.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/tmp/ipykernel_25/136545975.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Batch 300/2874 - Loss: 3.2830\n",
      "Epoch 1/3 - Batch 600/2874 - Loss: 3.2750\n",
      "Epoch 1/3 - Batch 900/2874 - Loss: 3.2642\n",
      "Epoch 1/3 - Batch 1200/2874 - Loss: 3.2710\n",
      "Epoch 1/3 - Batch 1500/2874 - Loss: 3.2573\n",
      "Epoch 1/3 - Batch 1800/2874 - Loss: 3.2566\n",
      "Epoch 1/3 - Batch 2100/2874 - Loss: 3.2492\n",
      "Epoch 1/3 - Batch 2400/2874 - Loss: 3.2506\n",
      "Epoch 1/3 - Batch 2700/2874 - Loss: 3.2443\n",
      "Epoch 2/3 - Batch 300/2874 - Loss: 3.1997\n",
      "Epoch 2/3 - Batch 600/2874 - Loss: 3.2045\n",
      "Epoch 2/3 - Batch 900/2874 - Loss: 3.1881\n",
      "Epoch 2/3 - Batch 1200/2874 - Loss: 3.1610\n",
      "Epoch 2/3 - Batch 1500/2874 - Loss: 3.1683\n",
      "Epoch 2/3 - Batch 1800/2874 - Loss: 3.1562\n",
      "Epoch 2/3 - Batch 2100/2874 - Loss: 3.1669\n",
      "Epoch 2/3 - Batch 2400/2874 - Loss: 3.1704\n",
      "Epoch 2/3 - Batch 2700/2874 - Loss: 3.1606\n",
      "Epoch 3/3 - Batch 300/2874 - Loss: 3.1201\n",
      "Epoch 3/3 - Batch 600/2874 - Loss: 3.1187\n",
      "Epoch 3/3 - Batch 900/2874 - Loss: 3.0963\n",
      "Epoch 3/3 - Batch 1200/2874 - Loss: 3.0582\n",
      "Epoch 3/3 - Batch 1500/2874 - Loss: 3.1017\n",
      "Epoch 3/3 - Batch 1800/2874 - Loss: 3.0905\n",
      "Epoch 3/3 - Batch 2100/2874 - Loss: 3.1144\n",
      "Epoch 3/3 - Batch 2400/2874 - Loss: 3.0956\n",
      "Epoch 3/3 - Batch 2700/2874 - Loss: 3.0968\n"
     ]
    }
   ],
   "source": [
    "# Replace with your actual number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "        # Move data to GPU\n",
    "        batch = {key: val.to('cuda') for key, val in batch.items()}\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (batch_idx + 1) % 300 == 0:  \n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs} - Batch {batch_idx + 1}/{len(train_loader)} - Loss: {total_loss / 100:.4f}\")\n",
    "            total_loss = 0.0\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85a0e3f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T11:58:35.038417Z",
     "iopub.status.busy": "2024-07-05T11:58:35.038092Z",
     "iopub.status.idle": "2024-07-05T11:58:35.048023Z",
     "shell.execute_reply": "2024-07-05T11:58:35.047060Z"
    },
    "papermill": {
     "duration": 0.027506,
     "end_time": "2024-07-05T11:58:35.050188",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.022682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a0a4e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T11:58:35.080856Z",
     "iopub.status.busy": "2024-07-05T11:58:35.080609Z",
     "iopub.status.idle": "2024-07-05T11:58:35.172904Z",
     "shell.execute_reply": "2024-07-05T11:58:35.171970Z"
    },
    "papermill": {
     "duration": 0.110303,
     "end_time": "2024-07-05T11:58:35.175149",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.064846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/709883472.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Ensure batch is a dictionary\n",
    "        if isinstance(batch, dict):\n",
    "            # Move batch to GPU if available\n",
    "            batch = {key: val.to('cuda') for key, val in batch.items()}\n",
    "\n",
    "            # Make predictions\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "            # Append probabilities to the list\n",
    "            all_predictions.append(probabilities.cpu().numpy())\n",
    "        else:\n",
    "            print(f\"Encountered a non-dict batch: {batch}\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "# Prepare DataFrame with predictions\n",
    "submission = pd.DataFrame(all_predictions, columns=['response_b_len', 'prompt_len', 'winner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5092036b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T11:58:35.206841Z",
     "iopub.status.busy": "2024-07-05T11:58:35.206578Z",
     "iopub.status.idle": "2024-07-05T11:58:35.217069Z",
     "shell.execute_reply": "2024-07-05T11:58:35.216172Z"
    },
    "papermill": {
     "duration": 0.02841,
     "end_time": "2024-07-05T11:58:35.219328",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.190918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_b_len</th>\n",
       "      <th>prompt_len</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266004</td>\n",
       "      <td>0.288333</td>\n",
       "      <td>0.445663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.484899</td>\n",
       "      <td>0.216474</td>\n",
       "      <td>0.298627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.360647</td>\n",
       "      <td>0.332232</td>\n",
       "      <td>0.307121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response_b_len  prompt_len    winner\n",
       "0        0.266004    0.288333  0.445663\n",
       "1        0.484899    0.216474  0.298627\n",
       "2        0.360647    0.332232  0.307121"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43b1c4fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-05T11:58:35.250825Z",
     "iopub.status.busy": "2024-07-05T11:58:35.250571Z",
     "iopub.status.idle": "2024-07-05T11:58:35.257721Z",
     "shell.execute_reply": "2024-07-05T11:58:35.256803Z"
    },
    "papermill": {
     "duration": 0.024952,
     "end_time": "2024-07-05T11:58:35.259890",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.234938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdae47",
   "metadata": {
    "papermill": {
     "duration": 0.014502,
     "end_time": "2024-07-05T11:58:35.289613",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.275111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234590ae",
   "metadata": {
    "papermill": {
     "duration": 0.015436,
     "end_time": "2024-07-05T11:58:35.319799",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.304363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643da39",
   "metadata": {
    "papermill": {
     "duration": 0.014553,
     "end_time": "2024-07-05T11:58:35.349044",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.334491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a149d8",
   "metadata": {
    "papermill": {
     "duration": 0.014582,
     "end_time": "2024-07-05T11:58:35.378229",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.363647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f545a2",
   "metadata": {
    "papermill": {
     "duration": 0.014503,
     "end_time": "2024-07-05T11:58:35.407627",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.393124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a65767",
   "metadata": {
    "papermill": {
     "duration": 0.014281,
     "end_time": "2024-07-05T11:58:35.436783",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.422502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6e5ea",
   "metadata": {
    "papermill": {
     "duration": 0.014215,
     "end_time": "2024-07-05T11:58:35.465658",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.451443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689a667",
   "metadata": {
    "papermill": {
     "duration": 0.014762,
     "end_time": "2024-07-05T11:58:35.495812",
     "exception": false,
     "start_time": "2024-07-05T11:58:35.481050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 1455358,
     "sourceId": 2468672,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15604.816752,
   "end_time": "2024-07-05T11:58:38.665979",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-05T07:38:33.849227",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
